# ğŸš€ ExtensÃµes de ResiliÃªncia e Monitoramento

## ğŸ“‹ VisÃ£o Geral

Este documento descreve as extensÃµes implementadas para completar o sistema de monitoramento, incluindo:

- âœ… **Health Checks** em todos os serviÃ§os
- âœ… **Circuit Breakers** para isolamento de falhas
- âœ… **MÃ©tricas de Uptime/Downtime**
- âœ… **MÃ©tricas de tempo de recuperaÃ§Ã£o**
- âœ… **MÃ©tricas de dependÃªncias entre serviÃ§os**
- âœ… **Alertas automÃ¡ticos**
- âœ… **Dashboard enhanced do Grafana**

## ğŸ¥ Health Checks

### ImplementaÃ§Ã£o
Cada serviÃ§o agora possui um endpoint `/health` que verifica:
- Conectividade com banco de dados
- Conectividade com RabbitMQ
- Status geral do serviÃ§o

### MÃ©tricas Geradas
```promql
# Status de saÃºde (1=healthy, 0=unhealthy)
order_service_health_status
payment_service_health_status
notification_service_health_status
```

### Exemplo de Resposta
```json
{
  "status": "healthy",
  "timestamp": 1628720400.123,
  "uptime": 3600.5,
  "dependencies": {
    "database": "healthy",
    "rabbitmq": "healthy"
  }
}
```

## ğŸ”Œ Circuit Breakers

### Funcionalidades
- **DetecÃ§Ã£o automÃ¡tica** de falhas repetidas
- **Fail-fast** quando dependÃªncias estÃ£o indisponÃ­veis
- **RecuperaÃ§Ã£o automÃ¡tica** apÃ³s timeout configurado
- **MÃ©tricas detalhadas** de estado e performance

### Estados
- `CLOSED (0)`: OperaÃ§Ã£o normal
- `OPEN (1)`: Circuito aberto, falhando rapidamente
- `HALF_OPEN (2)`: Testando recuperaÃ§Ã£o

### MÃ©tricas Geradas
```promql
# Estado do circuit breaker por dependÃªncia
order_service_circuit_breaker_state{dependency="database"}
payment_service_circuit_breaker_state{dependency="rabbitmq"}

# Chamadas para dependÃªncias
order_service_dependency_calls_total{dependency="database",status="success"}
payment_service_dependency_calls_total{dependency="rabbitmq",status="failure"}
```

### ConfiguraÃ§Ã£o
```python
# Exemplo de circuit breaker para banco de dados
database_circuit_breaker = CircuitBreaker(
    name="payment_database",
    failure_threshold=3,  # Abre apÃ³s 3 falhas
    timeout=30.0         # Tenta recuperar apÃ³s 30s
)
```

## â±ï¸ MÃ©tricas de Uptime e Tempo de RecuperaÃ§Ã£o

### Uptime por ServiÃ§o
```promql
# Tempo de atividade em segundos
order_service_uptime_seconds
payment_service_uptime_seconds
notification_service_uptime_seconds
```

### Tempo de RecuperaÃ§Ã£o
```promql
# DistribuiÃ§Ã£o do tempo de recuperaÃ§Ã£o
histogram_quantile(0.95, rate(payment_service_recovery_time_seconds_bucket[5m]))
histogram_quantile(0.50, rate(order_service_recovery_time_seconds_bucket[5m]))
```

## ğŸ”— MÃ©tricas de Desacoplamento

### ComunicaÃ§Ã£o AssÃ­ncrona
```promql
# Sucesso/falha no processamento de mensagens
order_service_rabbitmq_messages_total{type="payment_order",status="success"}
payment_service_rabbitmq_messages_total{type="payment_order",status="error"}

# Profundidade das filas
rabbitmq_queue_messages{queue="order_payment"}
```

### Taxa de Sucesso de DependÃªncias
```promql
# Taxa de sucesso por dependÃªncia
sum(rate(payment_service_dependency_calls_total{status="success"}[5m])) /
sum(rate(payment_service_dependency_calls_total[5m]))
```

## ğŸš¨ Sistema de Alertas

### Grupos de Alertas Implementados

#### 1. Health Alerts
- **ServiceDown**: ServiÃ§o completamente indisponÃ­vel
- **ServiceUnhealthy**: Health check falhando

#### 2. Performance Alerts
- **HighResponseTime**: LatÃªncia P95 > 2 segundos
- **HighErrorRate**: Taxa de erro HTTP 5xx > 5%

#### 3. Circuit Breaker Alerts
- **CircuitBreakerOpen**: Circuit breaker em estado aberto
- **CircuitBreakerHalfOpen**: Circuit breaker testando recuperaÃ§Ã£o

#### 4. Dependency Alerts
- **LowDependencySuccessRate**: Taxa de sucesso < 90%
- **HighMessageQueueDepth**: Muitas mensagens acumuladas

#### 5. Recovery Alerts
- **SlowRecoveryTime**: Tempo de recuperaÃ§Ã£o P95 > 10 segundos

#### 6. Business Alerts
- **HighMessageProcessingFailureRate**: Falha no processamento > 10%

### Exemplo de Alerta
```yaml
- alert: CircuitBreakerOpen
  expr: payment_service_circuit_breaker_state == 1
  for: 0s
  labels:
    severity: critical
  annotations:
    summary: "Circuit breaker is open"
    description: "Circuit breaker for {{ $labels.dependency }} is open"
```

## ğŸ“Š Dashboard Enhanced do Grafana

### Novos PainÃ©is Adicionados

1. **Service Health Status**: Status em tempo real
2. **Service Uptime**: Tempo de atividade
3. **Circuit Breaker Status**: Estado dos circuit breakers
4. **HTTP Error Rate**: Taxa de erros 5xx
5. **Message Queue Processing**: Processamento de mensagens
6. **Recovery Time Distribution**: DistribuiÃ§Ã£o do tempo de recuperaÃ§Ã£o
7. **Dependency Call Success Rate**: Taxa de sucesso das dependÃªncias
8. **RabbitMQ Queue Depth**: Profundidade das filas

### Recursos do Dashboard
- **VisualizaÃ§Ã£o em tempo real** com refresh de 5s
- **Mapeamento de estados** (Healthy/Unhealthy, Circuit Breaker states)
- **MÃºltiplas sÃ©ries temporais** para comparaÃ§Ã£o
- **Percentis de latÃªncia** (P50, P95)

## ğŸ§ª Como Testar

### 1. Script Automatizado
```bash
./test-resilience.sh
```

### 2. Testes Manuais

#### Testar Health Checks
```bash
# Verificar health check de cada serviÃ§o
curl http://localhost/orders/health
curl http://localhost/payments/health
curl http://localhost/notifications/health
```

#### Simular Falhas
```bash
# Parar banco de dados para testar circuit breaker
docker-compose stop db-payment-service

# Verificar mÃ©tricas de circuit breaker
curl http://localhost/payments/metrics | grep circuit_breaker_state
```

#### Verificar Alertas
```bash
# Acessar alertas no Prometheus
curl http://localhost:9090/api/v1/alerts
```

## ğŸ“ˆ Queries Ãšteis

### Availabilidade por ServiÃ§o
```promql
avg_over_time(order_service_health_status[1h]) * 100
```

### MTTR (Mean Time To Recovery)
```promql
avg(payment_service_recovery_time_seconds)
```

### Taxa de Falha de Circuit Breakers
```promql
sum(rate(payment_service_dependency_calls_total{status="failure"}[5m])) /
sum(rate(payment_service_dependency_calls_total[5m]))
```

### Isolamento de Falhas (Circuit Breaker Efficiency)
```promql
sum(increase(payment_service_circuit_breaker_state[1h]) > 0) /
sum(increase(payment_service_dependency_calls_total{status="failure"}[1h])) * 100
```

## ğŸ”§ ConfiguraÃ§Ã£o e CustomizaÃ§Ã£o

### Ajustar Circuit Breaker
```python
# No arquivo shared/circuit_breaker.py
CircuitBreaker(
    name="custom_dependency",
    failure_threshold=5,    # NÃºmero de falhas para abrir
    timeout=60.0,          # Tempo para tentar recuperar (segundos)
    expected_exception=Exception  # Tipo de exceÃ§Ã£o a tratar
)
```

### Adicionar Novas MÃ©tricas
```python
# No main.py de cada serviÃ§o
CUSTOM_METRIC = Counter(
    'service_custom_operations_total',
    'Description of custom metric',
    ['label1', 'label2']
)
```

### Personalizar Alertas
Edite o arquivo `prometheus/alert-rules.yml` para adicionar novos alertas ou ajustar thresholds.

## ğŸ“ Resumo de Atendimento aos Requisitos

| Requisito | Status | ImplementaÃ§Ã£o |
|-----------|--------|---------------|
| **Tempo de resposta mÃ©dio** | âœ… Completo | Histograms P50, P95, P99 |
| **Taxa de falhas HTTP 5xx** | âœ… Completo | Counters por status code |
| **Taxa de falhas mensageria** | âœ… Completo | Counters success/error |
| **Isolamento de falhas** | âœ… Completo | Circuit breakers automÃ¡ticos |
| **Desacoplamento** | âœ… Completo | MÃ©tricas de filas e dependÃªncias |
| **Tempo de recuperaÃ§Ã£o** | âœ… Completo | Histograms de recovery time |

## ğŸ¯ PrÃ³ximos Passos

1. **Implementar distributed tracing** (Jaeger/Zipkin)
2. **Adicionar logs centralizados** (ELK Stack)
3. **Implementar chaos engineering** (Chaos Monkey)
4. **Adicionar testes de carga automatizados** (k6/Locust)
5. **Implementar blue-green deployment** com mÃ©tricas

## ğŸ“ Troubleshooting

### Circuit Breakers nÃ£o funcionando
1. Verificar se as dependÃªncias estÃ£o registradas
2. Verificar logs dos serviÃ§os
3. Confirmar que as exceÃ§Ãµes estÃ£o sendo capturadas

### MÃ©tricas nÃ£o aparecendo
1. Verificar se endpoints `/metrics` estÃ£o acessÃ­veis
2. Confirmar configuraÃ§Ã£o do Prometheus
3. Verificar logs do Prometheus

### Alertas nÃ£o disparando
1. Verificar sintaxe das regras de alerta
2. Confirmar que o Prometheus carregou as regras
3. Verificar se as mÃ©tricas necessÃ¡rias existem

---

**ğŸ“§ Para suporte adicional, consulte os logs dos serviÃ§os e a documentaÃ§Ã£o do Prometheus/Grafana.**
